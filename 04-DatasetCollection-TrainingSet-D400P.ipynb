{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8695e807",
   "metadata": {},
   "source": [
    "# Training Set Creation (Final Model)\n",
    "\n",
    "This notebook constructs the training dataset that will later be used to build and evaluate the final model.  \n",
    "\n",
    "The **input file** is:  \n",
    "- `dataset_dfs10000.pkl` (containing the raw sequences).  \n",
    "\n",
    "The **output file** generated by this notebook is:  \n",
    "- `trainingDataMax10000.csv`.  \n",
    "\n",
    "---\n",
    "\n",
    "## Metrics Required\n",
    "\n",
    "In order to train the model, it is necessary to determine the **most comparison-efficient sorting algorithm** for each sequence, which serves as the target label. As input features, we employ the **sampled presortedness metrics** (**Runs** and **Deletions**) together with the **sequence length**.  \n",
    "\n",
    "For the evaluation of the model, we additionally record the **number of comparisons required** to compute the presortedness metrics, as this reflects the computational overhead associated with feature extraction.  \n",
    "\n",
    "---\n",
    "\n",
    "## Sampling Strategies\n",
    "\n",
    "To address **RQ3**, the notebook implements different sampling strategies and sample sizes. Specifically, the following methods can be applied:  \n",
    "\n",
    "- `sampling_10_step(sample_size)`  \n",
    "- `sampling_30_step(sample_size)`  \n",
    "\n",
    "These procedures allow us to investigate how different sampling strategies and sample sizes influence the model.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfeb51-c478-462d-baec-20b3057d995a",
   "metadata": {},
   "source": [
    "## Sorting algorithm (comparison benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b6059-46dd-418b-bcbd-1f750bba52f6",
   "metadata": {},
   "source": [
    "### Insertion sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403be40f-b8d1-4ba6-b73d-66056e6b4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(A):\n",
    "    comparisons = 0\n",
    "    for i in range(1, len(A)):\n",
    "        key = A[i]\n",
    "        j = i - 1\n",
    "        comparisons += 1\n",
    "        while j >= 0 and A[j] > key:\n",
    "            comparisons += 1\n",
    "            A[j + 1] = A[j]\n",
    "            j -= 1\n",
    "        A[j + 1] = key\n",
    "    return comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e98ec7-b16c-4170-9ad9-8ad1180b41a1",
   "metadata": {},
   "source": [
    "### Merge sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e64fbab-fb09-41cb-bfa8-b90775d246d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(A):\n",
    "    if len(A) <= 1:\n",
    "        return 0\n",
    "    mid = len(A) // 2\n",
    "    left = A[:mid]\n",
    "    right = A[mid:]\n",
    "\n",
    "    comparecount = merge_sort(left) + merge_sort(right)\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    \n",
    "    while i < len(left) and j < len(right):\n",
    "        comparecount += 1\n",
    "        if left[i] <= right[j]:\n",
    "            A[k] = left[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            A[k] = right[j]\n",
    "            j += 1\n",
    "        k += 1\n",
    "\n",
    "    while i < len(left):\n",
    "        comparecount += 1\n",
    "        A[k] = left[i]\n",
    "        i += 1\n",
    "        k += 1\n",
    "\n",
    "    while j < len(right):\n",
    "        comparecount += 1\n",
    "        A[k]=right[j]\n",
    "        j += 1\n",
    "        k += 1\n",
    "\n",
    "    return comparecount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af037496-5aff-4fb8-85cb-4f395fa0f6df",
   "metadata": {},
   "source": [
    "### Timsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e187cb-fe22-4106-9445-83ac28931e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMUM = 32\n",
    "\n",
    "def find_minrun(n): \n",
    "    r = 0\n",
    "    while n >= MINIMUM: \n",
    "        r |= n & 1\n",
    "        n >>= 1\n",
    "    return n + r \n",
    "\n",
    "def tim_insertion_sort(array, left, right): \n",
    "    global comparisons\n",
    "    for i in range(left + 1, right + 1):\n",
    "        key = array[i]\n",
    "        j = i - 1\n",
    "        comparisons += 1\n",
    "        while j >= left and key < array[j]:\n",
    "            array[j + 1] = array[j]\n",
    "            j -= 1\n",
    "            comparisons += 1\n",
    "        array[j + 1] = key\n",
    "    return array\n",
    "              \n",
    "def tim_merge(array, l, m, r): \n",
    "    global comparisons\n",
    "    array_length1 = m - l + 1\n",
    "    array_length2 = r - m \n",
    "    left = []\n",
    "    right = []\n",
    "    for i in range(array_length1): \n",
    "        left.append(array[l + i]) \n",
    "    for i in range(array_length2): \n",
    "        right.append(array[m + 1 + i]) \n",
    "  \n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = l\n",
    "   \n",
    "    while j < array_length2 and i < array_length1: \n",
    "        if left[i] <= right[j]: \n",
    "            array[k] = left[i] \n",
    "            i += 1\n",
    "        else: \n",
    "            array[k] = right[j] \n",
    "            j += 1\n",
    "        k += 1\n",
    "        comparisons += 1\n",
    "  \n",
    "    while i < array_length1: \n",
    "        array[k] = left[i] \n",
    "        k += 1\n",
    "        i += 1\n",
    "        comparisons += 1\n",
    "  \n",
    "    while j < array_length2: \n",
    "        array[k] = right[j] \n",
    "        k += 1\n",
    "        j += 1\n",
    "        comparisons += 1\n",
    "  \n",
    "def timsort(array): \n",
    "    n = len(array) \n",
    "    minrun = find_minrun(n) \n",
    "  \n",
    "    for start in range(0, n, minrun): \n",
    "        end = min(start + minrun - 1, n - 1) \n",
    "        tim_insertion_sort(array, start, end) \n",
    "   \n",
    "    size = minrun \n",
    "    while size < n: \n",
    "        for left in range(0, n, 2 * size): \n",
    "            mid = min(n - 1, left + size - 1) \n",
    "            right = min((left + 2 * size - 1), (n - 1)) \n",
    "            tim_merge(array, left, mid, right) \n",
    "        size = 2 * size\n",
    "\n",
    "    return comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd61a2-17f3-412e-a74a-2b35fb2c1e57",
   "metadata": {},
   "source": [
    "## PRESORTEDNESS Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2221fa5-9682-440d-831d-420fae7fb82a",
   "metadata": {},
   "source": [
    "### Number of Runs\n",
    "The number of runs, is the number of increasing sequences in an array minus one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a82728f-3b24-4ae8-b143-ba12845c98b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def runs(arr):\n",
    "    count = 0\n",
    "\n",
    "    for key in range(1,len(arr)):\n",
    "        if arr[key] < arr[key-1]:\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aaea76",
   "metadata": {},
   "source": [
    "Number of comparisons needed for Runs computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b40527b0-bfbb-4454-8ae5-838b92a3b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runs_comp(arr):\n",
    "    count = 0\n",
    "    comparisons = 0\n",
    "    for key in range(1,len(arr)):\n",
    "        comparisons += 1\n",
    "        if arr[key] < arr[key-1]:\n",
    "            count += 1\n",
    "\n",
    "    return comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a80848-99c6-4515-ad3c-d33c07bc5873",
   "metadata": {},
   "source": [
    "### Number of Deletions\n",
    "The minimum number of elements that need to be removed from array to obtain a sorted sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc96eae-1ce0-4136-a336-57f492dba90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def deletions(arr):\n",
    "    def ceil_index(sub, val):\n",
    "        l, r = 0, len(sub)-1\n",
    "        while l <= r:\n",
    "            mid = (l + r) // 2\n",
    "            if sub[mid] >= val:\n",
    "                r = mid - 1\n",
    "            else:\n",
    "                l = mid + 1\n",
    "        return l\n",
    " \n",
    "    sub = [arr[0]]\n",
    "    for i in range(1, len(arr)):\n",
    "        if arr[i] >= sub[-1]:\n",
    "            sub.append(arr[i])\n",
    "        else:\n",
    "            sub[ceil_index(sub, arr[i])] = arr[i]\n",
    " \n",
    "    return len(arr) - len(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15a86d",
   "metadata": {},
   "source": [
    "Number of comparisons needed for Deletions computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d53b04d3-ac23-4144-b229-6adc3aeefe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletions_comp(arr):\n",
    "    global comparisons\n",
    "    comparisons = 0\n",
    "    def ceil_index(sub, val):\n",
    "        global comparisons\n",
    "        l, r = 0, len(sub)-1\n",
    "        while l <= r:\n",
    "            mid = (l + r) // 2\n",
    "            comparisons += 1\n",
    "            if sub[mid] >= val:\n",
    "                r = mid - 1\n",
    "            else:\n",
    "                l = mid + 1\n",
    "        return l\n",
    " \n",
    "    sub = [arr[0]]\n",
    "    for i in range(1, len(arr)):\n",
    "        comparisons += 1\n",
    "        if arr[i] >= sub[-1]:\n",
    "            sub.append(arr[i])\n",
    "        else:\n",
    "            sub[ceil_index(sub, arr[i])] = arr[i]\n",
    " \n",
    "    return comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145b04b-62a7-44fd-adfd-87b8933055f5",
   "metadata": {},
   "source": [
    "## Training Set creation (sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4332069-5f36-4f5c-89b6-dd5f3f30b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Dataset      Column       Algorithm  Comparisons  \\\n",
      "0     cp_ratings  Unnamed: 0  insertion_sort         1251   \n",
      "1     cp_ratings  max_rating      merge_sort        12976   \n",
      "2     cp_ratings    contest1      merge_sort        12976   \n",
      "3     cp_ratings    contest2      merge_sort        12976   \n",
      "4     cp_ratings    contest3      merge_sort        12976   \n",
      "...          ...         ...             ...          ...   \n",
      "1685       train      Pclass         timsort         6662   \n",
      "1686       train         Age      merge_sort         6830   \n",
      "1687       train       SibSp         timsort         6242   \n",
      "1688       train       Parch         timsort         5904   \n",
      "1689       train        Fare      merge_sort         6830   \n",
      "\n",
      "      deletions_val_distStatic  runs_val_distStatic  \\\n",
      "0                            0                    0   \n",
      "1                           31                   18   \n",
      "2                           31                   17   \n",
      "3                           33                   19   \n",
      "4                           31                   20   \n",
      "...                        ...                  ...   \n",
      "1685                        16                   12   \n",
      "1686                        28                   18   \n",
      "1687                        33                    7   \n",
      "1688                        32                    4   \n",
      "1689                        30                   19   \n",
      "\n",
      "      deletions_comp_distStatic  runs_comp_distStatic  arr_len   introsort  \\\n",
      "0                            39                    39     1252  1000000000   \n",
      "1                           129                    39     1252  1000000000   \n",
      "2                           133                    39     1252  1000000000   \n",
      "3                           132                    39     1252  1000000000   \n",
      "4                           128                    39     1252  1000000000   \n",
      "...                         ...                   ...      ...         ...   \n",
      "1685                         94                    39      714  1000000000   \n",
      "1686                        128                    39      714  1000000000   \n",
      "1687                        114                    39      714  1000000000   \n",
      "1688                        114                    39      714  1000000000   \n",
      "1689                        127                    39      714  1000000000   \n",
      "\n",
      "      insertion_sort  merge_sort  timsort  quick_sort  selection_sort  \n",
      "0               1251       12976     8701  1000000000      1000000000  \n",
      "1             392015       12976    14864  1000000000      1000000000  \n",
      "2             388750       12976    14754  1000000000      1000000000  \n",
      "3             395813       12976    14855  1000000000      1000000000  \n",
      "4             400835       12976    14895  1000000000      1000000000  \n",
      "...              ...         ...      ...         ...             ...  \n",
      "1685           83259        6830     6662  1000000000      1000000000  \n",
      "1686          121895        6830     8090  1000000000      1000000000  \n",
      "1687           68709        6830     6242  1000000000      1000000000  \n",
      "1688           56476        6830     5904  1000000000      1000000000  \n",
      "1689          127989        6830     8107  1000000000      1000000000  \n",
      "\n",
      "[1690 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "with open('dataset_dfs10000.pkl', 'rb') as f:\n",
    "    dataset_dfs = pickle.load(f)\n",
    "\n",
    "for key, df in dataset_dfs.items():\n",
    "    for column in df.columns:\n",
    "        arr = df[column].values\n",
    "        if len(arr) < 400:\n",
    "            continue\n",
    "        \n",
    "        # sorting algorithm comparison calculation\n",
    "        comp_merge = merge_sort(arr.copy())\n",
    "        comp_insertion = insertion_sort(arr.copy())\n",
    "        global comparisons\n",
    "        comparisons = 0\n",
    "        comp_tim = timsort(arr.copy())\n",
    "                \n",
    "        comparison_counts = {\n",
    "            'insertion_sort': comp_insertion,\n",
    "            'merge_sort': comp_merge,\n",
    "            'timsort': comp_tim,\n",
    "        }\n",
    "\n",
    "        min_algorithm = min(comparison_counts, key=comparison_counts.get)\n",
    "        min_comparisons = comparison_counts[min_algorithm]\n",
    "\n",
    "        # RQ3 sampling_10_step and sampling_30_step have been used to evaluate optimal sampling strategy and sample size\n",
    "\n",
    "        def sampling_10_step(sample_size):\n",
    "            return [arr[i] for i in range(0, sample_size * 10, 10)]\n",
    "\n",
    "        def sampling_30_step(sample_size):\n",
    "            step = 30\n",
    "\n",
    "            sample = arr[: (sample_size - 10) * step : step]\n",
    "\n",
    "            reverse_sampled = arr[-10 * step::step]\n",
    "    \n",
    "            result = np.concatenate((sample, reverse_sampled))\n",
    "            \n",
    "            return result\n",
    "\n",
    "        # RQ4 sampling for final model\n",
    "\n",
    "        def samplingDistStatic():\n",
    "            first_20 = arr[:200:10]\n",
    "\n",
    "            middle_start = len(arr) // 2  \n",
    "            middle_10 = arr[middle_start:middle_start + 100 :10]\n",
    "\n",
    "            last_10 = arr[-100::10]\n",
    "\n",
    "            return np.concatenate([first_20, middle_10, last_10])\n",
    "\n",
    "        results.append({\n",
    "            'Dataset': key,\n",
    "            'Column': column,\n",
    "            'Algorithm': min_algorithm,\n",
    "            'Comparisons': min_comparisons,\n",
    "            \n",
    "            'deletions_val_distStatic': deletions(samplingDistStatic()),\n",
    "            'runs_val_distStatic': runs(samplingDistStatic()),\n",
    "            'deletions_comp_distStatic': deletions_comp(samplingDistStatic()),\n",
    "            'runs_comp_distStatic': runs_comp(samplingDistStatic()),\n",
    "            \n",
    "            'arr_len': len(arr),\n",
    "            \n",
    "            'insertion_sort': comp_insertion,\n",
    "            'merge_sort': comp_merge,\n",
    "            'timsort': comp_tim,\n",
    "        })\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n",
    "df_results.to_csv('trainingDataMax10000.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
