{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261344a8-73b3-41bb-a8ae-5b2d45163fae",
   "metadata": {},
   "source": [
    "# RQ3: Sampling Strategy\n",
    "\n",
    "Experiments conducted to investigate how different sampling strategies and sample sizes influence the model.\n",
    "\n",
    "- Sampling strategy (sample size: 200 - 1000): every 10th element of the sequence until sample size is reached.\n",
    "- Sampling strategy (sample size: 1200 - 2000): every 30th element from the start and end of the sequence until the sample size is reached.\n",
    "\n",
    "The **input file** is:  \n",
    "- the `dataset_sequences/dataset_sequences_10k.pkl` containing the raw sequences.\n",
    "\n",
    "The **output files** computed by this notebook are:  \n",
    "- the `rq3_dataset/dataset_training_rq3_<length>_<sample size>.csv` containing presortedness features and labels for a fixed sequence length and sample size.\n",
    "- the `rq3_model/model_rq3...` the best model for each fixed sequence length and sample size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b4d59c-95bd-4c28-a8b6-7eb09238bdd3",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Installs the exact version of packages required for this notebook into the current Jupyter kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f82c6d-19e8-42bd-b045-8e3a32c3206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn==1.7.0\n",
    "%pip install pandas==2.2.3\n",
    "%pip install numpy==1.26.0\n",
    "%pip install tensorflow==2.15.0\n",
    "%pip install matplotlib==3.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464af252-abfc-43f6-91d3-d06d502654f4",
   "metadata": {},
   "source": [
    "## Create Datasets for Training, Validation, and Test\n",
    "\n",
    "For each fixed sequence length and sample size, a specific dataset is created that contains presortedness features and labels for a fixed sequence length and sample size.\n",
    "\n",
    "In order to train the model, it is necessary to determine the **most comparison-efficient sorting algorithm** (*Insertionsort*, *Mergesort*, *Timsort*) for each sequence, which serves as the target label. As input features, we employ the **sampled presortedness metrics** (*Runs* and *Deletions*).  \n",
    "\n",
    "For the evaluation of the model, we additionally record the **number of comparisons required** to compute the presortedness metrics, as this reflects the computational overhead associated with feature extraction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b920784-66f5-41c3-947c-2aa397cbeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from intellisorts_training_set import *\n",
    "\n",
    "dataset_path = 'dataset_sequences/dataset_sequences_10k.pkl'\n",
    "\n",
    "print(f\"Loading sequences {dataset_path} ...\")\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    dataset_10k_dfs = pickle.load(f)\n",
    "\n",
    "print(\"Sequences loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f16928-322b-44f1-aaa1-7a4c89756c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ3 sampling_10_step and sampling_30_step have been used to evaluate optimal sampling strategy and sample size\n",
    "step10 = sampling_strategy_10_step\n",
    "step30 = sampling_strategy_30_step\n",
    "\n",
    "length_and_sampling_strategy = [\n",
    "    (200, step10),\n",
    "    (400, step10),\n",
    "    (600, step10),\n",
    "    (800, step10),\n",
    "    (1000, step10),\n",
    "    (1200, step30),\n",
    "    (1400, step30),\n",
    "    (2000, step30)\n",
    "]\n",
    "sample_sizes = [5, 50]\n",
    "\n",
    "for sample_size in range(sample_sizes[0], sample_sizes[1] + 1):\n",
    "    for length, sampling_strategy in length_and_sampling_strategy:\n",
    "        df_results = compute_training_data(\n",
    "            dataset_dfs = dataset_10k_dfs,\n",
    "            min_length = length,\n",
    "            max_length = length,\n",
    "            sampling_strategy = sampling_strategy,\n",
    "            sample_size = sample_size\n",
    "        )\n",
    "        print()\n",
    "        print(f'Dataset D[{length}, {sample_size}]:', len(df_results))\n",
    "        df_results.to_csv(f'rq3_dataset/dataset_training_rq3_{length}_{sample_size}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0dac48-5448-4d2a-8cb3-a55d6dbf38ee",
   "metadata": {},
   "source": [
    "## Train and Evaluate Neural Network Model\n",
    "\n",
    "For each fixed sequence length and sample size, model training including hyperparameter optimization in a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9bed03-3c28-4b6d-bf0a-22192e7e42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from intellisorts_model_training import grid_search\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data_per_length = {}\n",
    "\n",
    "for length, _ in length_and_sampling_strategy:\n",
    "    data_per_length[length] = []\n",
    "\n",
    "for sample_size in range(sample_size[0], sample_size[1] + 1):\n",
    "    for length, _ in length_and_sampling_strategy:\n",
    "        \n",
    "        # load training dataset\n",
    "        df_results = pd.read_csv(f'rq3_dataset/dataset_training_rq3_{length}_{sample_size}.csv')\n",
    "        \n",
    "        # features\n",
    "        train_input = df_results[['Deletions', 'Runs','SequenceLength']]\n",
    "        train_output = df_results['Algorithm']\n",
    "        \n",
    "        # perform grid search\n",
    "        param_grid = {\n",
    "            'batch_size': [512],\n",
    "            'epochs': [500],\n",
    "            'layers': [4,6,8],\n",
    "            'layersize': [4,6,8]\n",
    "        }\n",
    "        \n",
    "        (\n",
    "            best_model,\n",
    "            scaler,\n",
    "            label_encoder,\n",
    "            test_accuracy,\n",
    "            test_indices,\n",
    "            test_true_algorithms,\n",
    "            test_predicted_algorithms\n",
    "        ) = grid_search(\n",
    "            'rq3_model/model_rq3',\n",
    "            train_input,\n",
    "            train_output,\n",
    "            param_grid\n",
    "        )\n",
    "\n",
    "        # evalute comparisons\n",
    "        test_set_df = df_results.iloc[test_indices]\n",
    "        test_set_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        c = []\n",
    "        t = []\n",
    "        \n",
    "        for index, row in test_set_df.iterrows():\n",
    "            c.append(row[test_predicted_algorithms[index] + \"_Comparisons\"])\n",
    "            t.append(row[test_true_algorithms[index] + \"_Comparisons\"])\n",
    "        \n",
    "        minimum_possible = round(np.sum(t)/len(test_set_df), 1)\n",
    "        algorithm_prediction_model = round(np.sum(c)/len(test_set_df), 1)\n",
    "        \n",
    "        def calculate_average(column_name):\n",
    "            return round(np.sum(test_set_df[column_name]) / len(test_set_df), 1)\n",
    "\n",
    "        deletions_comp_dist_avg = calculate_average('Deletions_Comparisons')\n",
    "        runs_comp_dist_avg = calculate_average('Runs_Comparisons')\n",
    "        presortedness_average_comp = runs_comp_dist_avg + deletions_comp_dist_avg\n",
    "\n",
    "        combined_comp = algorithm_prediction_model + presortedness_average_comp\n",
    "        \n",
    "        print('Minimum possible: ', minimum_possible)\n",
    "        print('Algorithm predicting model: ', algorithm_prediction_model)\n",
    "        print('Presortedness calculation comparisons: ', presortedness_average_comp)\n",
    "        print('Combined comparisons model: ', round(combined_comp, 1))\n",
    "\n",
    "        data = data_per_length[length]\n",
    "        data.append(\n",
    "            {\n",
    "                'accuracy': test_accuracy,\n",
    "                'sort_comparisons': algorithm_prediction_model,\n",
    "                'presortedness_comparisons': presortedness_average_comp,\n",
    "                'combined': combined_comp\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a7af3-624a-4e13-86fa-49a8b34d4b94",
   "metadata": {},
   "source": [
    "## Plot the Average Comparisons in Relation to the Sample Size\n",
    "\n",
    "Shows the average number of comparisons in relation to sample size for  each sequence length. (1) The blue area represents comparisons required to compute presortedness metrics. (2) The orange area shows comparisons required by the predicted sorting algorithm. (3) The blue line represents the total combined comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684dd5d5-a7da-4968-8284-42580171160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for length, _ in length_and_sampling_strategy:\n",
    "    print()\n",
    "    print(\"Sequence Length:\", length)\n",
    "    print()\n",
    "    \n",
    "    data = data_per_length[length]\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    display(df)\n",
    "    \n",
    "    # plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # density plot for 'combined'\n",
    "    plt.plot(df.index + 1, df['combined'], label='Additional Presortedness Comparisons', color='blue')\n",
    "    plt.fill_between(df.index + 1, df['combined'], color='blue', alpha=0.3)\n",
    "    \n",
    "    # density plot for 'presortedness_comparisons'\n",
    "    plt.plot(df.index + 1, df['combined'] - df['presortedness_comparisons'], label='Predicted algorithm Comparisons', color='orange')\n",
    "    plt.fill_between(df.index + 1, df['combined'] - df['presortedness_comparisons'], color='orange')\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.xlabel('Sample size')\n",
    "    plt.ylabel('Number of Comparisons')\n",
    "    plt.title('comparisons of different sample sizes')\n",
    "    plt.legend()\n",
    "    \n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5653989e-ebc4-45fd-886c-8af96cdbf99f",
   "metadata": {},
   "source": [
    "## Optimal Sample Size at Different Sequence Sizes\n",
    "\n",
    "Optimal sample sizes in relation to the size of the original sequence size. (1) For sequences up to 1000 elements, every 10th number was sampled (blue graph). (2) For sequences of size larger than 1000 elements, every 30th element was sampled (red graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e271d4-1f1c-467c-881d-6a6b2aa2b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_sizes = [200,400,600,800,1000]\n",
    "optimal_sample_size = [13,22,38,45,44]\n",
    "\n",
    "extended_array_sizes = [1200, 1400, 2000]\n",
    "extended_optimal_sample_size = [27, 34, 43]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(array_sizes, optimal_sample_size, marker='o', color='blue', label='Every 10th Number Sampling')\n",
    "\n",
    "plt.plot(extended_array_sizes, extended_optimal_sample_size, marker='o', color='red', label='Every 30th Number Sampling')\n",
    "\n",
    "plt.xticks(range(200, 2100, 200))\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Sequence Size')\n",
    "plt.ylabel('Optimal Sample Size')\n",
    "# plt.title('Optimal Sample Size by Sequence Size')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Print plot\n",
    "plt.rc('font', family='Lato', size=24)  # only applies on a second run\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
