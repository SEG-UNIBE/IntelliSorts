{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2: Feature Engineering\n",
    "\n",
    "---\n",
    "\n",
    "Investigates which **combination of presortedness metrics** provides the most efficient prediction, **sampled metrics** are employed rather than full-sequence metrics.\n",
    "\n",
    "- Specifically, a **sample size of 10** is used, with values drawn at intervals of 20 positions in the sequence.  \n",
    "- For the evaluation of presortedness metric combinations, the **number of comparisons required** to compute the metrics is recorded, as this reflects the computational overhead of feature extraction.  \n",
    "\n",
    "The **input file** is:  \n",
    "- the `dataset_sequences/dataset_sequences_200.pkl` containing the raw sequences.\n",
    "\n",
    "The **output files** computed by this notebook are:  \n",
    "- the `rq2_dataset/dataset_training_rq2_200.csv` containing presortedness features and labels.\n",
    "- the `rq2_model/model_rq2...` the best model for each presortedness combiniation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Installs the exact version of packages required for this notebook into the current Jupyter kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn==1.7.0\n",
    "%pip install pandas==2.2.3\n",
    "%pip install numpy==1.26.0\n",
    "%pip install tensorflow==2.15.0\n",
    "%pip install matplotlib==3.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset for Training, Validation, and Test\n",
    "\n",
    "In order to train the model, it is necessary to determine the **most comparison-efficient sorting algorithm** (*Introsort*, *Insertionsort*, *Mergesort*, *Timsort*, *Quicksort*) for each sequence, which serves as the target label. As input features, we employ the **sampled presortedness metrics** (*Runs*, *Deletions*, *Inversions*, and *Inversion Distance*).  \n",
    "\n",
    "For the evaluation of the model, we additionally record the **number of comparisons required** to compute the presortedness metrics, as this reflects the computational overhead associated with feature extraction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from intellisorts_training_set import *\n",
    "\n",
    "dataset_path = 'dataset_sequences/dataset_sequences_200.pkl'\n",
    "\n",
    "print(f\"Loading sequences {dataset_path} ...\")\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    dataset_200_dfs = pickle.load(f)\n",
    "\n",
    "print(\"Sequences loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ2 distributed sampling strategy for presortedness combination assessment\n",
    "df_results = compute_training_data_extended(\n",
    "    dataset_dfs = dataset_200_dfs,\n",
    "    min_length = 200,\n",
    "    max_length = 200,\n",
    "    sampling_strategy = sampling_strategy_evenly,\n",
    "    sample_size = 10\n",
    ")\n",
    "\n",
    "print(\"Dataset D200:\", len(df_results))\n",
    "df_results.to_csv('rq2_dataset/dataset_training_rq2_200.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Neural Network Model\n",
    "\n",
    "Model training including hyperparameter optimization in a grid search. Finally, shows an algorithm prediction summary that compares the **actual vs. predicted counts** for each sorting algorithm in the test set and reports the number of **true positives** per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from intellisorts_model_training import grid_search\n",
    "\n",
    "# load training dataset\n",
    "df_results = pd.read_csv('rq2_dataset/dataset_training_rq2_200.csv')\n",
    "\n",
    "# combinations\n",
    "runs_rem = ['Runs', 'Deletions']\n",
    "inv_dis = ['Inversions', 'InversionDistance']\n",
    "inv_dis_runs = ['Inversions', 'InversionDistance', 'Runs']\n",
    "inv_dis_rem = ['Inversions', 'InversionDistance', 'Deletions']\n",
    "inv_dis_runs_rem = ['Inversions', 'InversionDistance', 'Runs', 'Deletions']\n",
    "\n",
    "# features\n",
    "train_input_runs_rem = df_results[runs_rem]\n",
    "train_input_inv_dis = df_results[inv_dis]\n",
    "train_input_inv_dis_runs = df_results[inv_dis_runs]\n",
    "train_input_inv_dis_rem = df_results[inv_dis_rem]\n",
    "train_input_inv_dis_runs_rem = df_results[inv_dis_runs_rem]\n",
    "\n",
    "train_output = df_results['Algorithm']\n",
    "\n",
    "# perform grid search\n",
    "param_grid = {\n",
    "    'batch_size': [512],\n",
    "    'epochs': [500],\n",
    "    'layers': [8],#[4,5,6,7,8],\n",
    "    'layersize': [8]#[1,2,3,4,5,6,7,8,9,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model for Combination: Runs, Rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination: Runs, Rem\n",
    "(\n",
    "    best_model_runs_rem,\n",
    "    scaler_runs_rem,\n",
    "    label_encoder_runs_rem,\n",
    "    test_accuracy_runs_rem,\n",
    "    test_indices_runs_rem,\n",
    "    test_true_algorithms_runs_rem,\n",
    "    test_predicted_algorithms_runs_rem\n",
    ") = grid_search(\n",
    "    'rq2_model/model_rq2_runs_rem',\n",
    "    train_input_runs_rem,\n",
    "    train_output,\n",
    "    param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model for Combination: Inv, Dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination: Inv, Dis\n",
    "(\n",
    "    best_model_inv_dis,\n",
    "    scaler_inv_dis,\n",
    "    label_encoder_inv_dis,\n",
    "    test_accuracy_inv_dis,\n",
    "    test_indices_inv_dis,\n",
    "    test_true_algorithms_inv_dis,\n",
    "    test_predicted_algorithms_inv_dis\n",
    ") = grid_search(\n",
    "    'rq2_model/model_rq2_inv_dis',\n",
    "    train_input_inv_dis,\n",
    "    train_output,\n",
    "    param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model for Combination: Inv, Dis, Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination: Inv, Dis, Runs\n",
    "(\n",
    "    best_model_inv_dis_runs,\n",
    "    scaler_inv_dis_runs,\n",
    "    label_encoder_inv_dis_runs,\n",
    "    test_accuracy_inv_dis_runs,\n",
    "    test_indices_inv_dis_runs,\n",
    "    test_true_algorithms_inv_dis_runs,\n",
    "    test_predicted_algorithms_inv_dis_runs\n",
    ") = grid_search(\n",
    "    'rq2_model/model_rq2_inv_dis',\n",
    "    train_input_inv_dis_runs,\n",
    "    train_output,\n",
    "    param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model for Combination: Inv, Dis, Rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination: Inv, Dis, Rem\n",
    "(\n",
    "    best_model_inv_dis_rem,\n",
    "    scaler_inv_dis_rem,\n",
    "    label_encoder_inv_dis_rem,\n",
    "    test_accuracy_inv_dis_rem,\n",
    "    test_indices_inv_dis_rem,\n",
    "    test_true_algorithms_inv_dis_rem,\n",
    "    test_predicted_algorithms_inv_dis_rem\n",
    ") = grid_search(\n",
    "    'rq2_model/model_rq2_inv_dis_rem',\n",
    "    train_input_inv_dis_rem,\n",
    "    train_output,\n",
    "    param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model for Combination: Inv, Dis, Runs, Rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination: Inv, Dis, Runs, Rem\n",
    "(\n",
    "    best_model_inv_dis_runs_rem,\n",
    "    scaler_inv_dis_runs_rem,\n",
    "    label_encoder_inv_dis_runs_rem,\n",
    "    test_accuracy_inv_dis_runs_rem,\n",
    "    test_indices_inv_dis_runs_rem,\n",
    "    test_true_algorithms_inv_dis_runs_rem,\n",
    "    test_predicted_algorithms_inv_dis_runs_rem\n",
    ") = grid_search(\n",
    "    'rq2_model/model_rq2_inv_dis_runs_rem',\n",
    "    train_input_inv_dis_runs_rem,\n",
    "    train_output,\n",
    "    param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The average comparisons needed for the sorting algorithm prediction in comparison to the accuracy of the best model after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def avg_comparisons_of_predicted_algorithms(df_results, test_indices, test_predicted_algorithms):\n",
    "    test_set_df = df_results.iloc[test_indices]\n",
    "    test_set_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    c = []\n",
    "    for index, row in test_set_df.iterrows():\n",
    "        c.append(row[test_predicted_algorithms[index] + \"_Comparisons\"])\n",
    "    \n",
    "    return round(np.sum(c)/len(test_set_df), 1)\n",
    "\n",
    "\n",
    "def avg_comparisons_of_presortednes_computation(df_results, combinations):\n",
    "    return df_results[[item + '_Comparisons' for item in combinations]].stack().mean()\n",
    "\n",
    "    \n",
    "# Store results in a list of dicts\n",
    "results = []\n",
    "\n",
    "# Define your combos and variable names\n",
    "combinations = [\n",
    "    (\"runs_rem\", test_accuracy_runs_rem, test_indices_runs_rem, test_predicted_algorithms_runs_rem),\n",
    "    (\"inv_dis\", test_accuracy_inv_dis, test_indices_inv_dis, test_predicted_algorithms_inv_dis),\n",
    "    (\"inv_dis_runs\", test_accuracy_inv_dis_runs, test_indices_inv_dis_runs, test_predicted_algorithms_inv_dis_runs),\n",
    "    (\"inv_dis_rem\", test_accuracy_inv_dis_rem, test_indices_inv_dis_rem, test_predicted_algorithms_inv_dis_rem),\n",
    "    (\"inv_dis_runs_rem\", test_accuracy_inv_dis_runs_rem, test_indices_inv_dis_runs_rem, test_predicted_algorithms_inv_dis_runs_rem),\n",
    "]\n",
    "\n",
    "# Loop and compute metrics for each combo\n",
    "for name, test_acc, test_idx, test_pred in combinations:\n",
    "    avg_presorted = avg_comparisons_of_presortednes_computation(df_results, eval(name))\n",
    "    avg_predicted = avg_comparisons_of_predicted_algorithms(df_results, test_idx, test_pred)\n",
    "    total_comparisons = avg_presorted + avg_predicted  # sum of both\n",
    "    \n",
    "    results.append({\n",
    "        \"Combination\": name,\n",
    "        \"Test Accuracy\": test_acc,\n",
    "        \"Avg Comparisons (Presortedness)\": round(avg_presorted, 2),\n",
    "        \"Avg Comparisons (Predicted Algo)\": avg_predicted,\n",
    "        \"Total Avg Comparisons\": round(total_comparisons, 2)\n",
    "    })\n",
    "\n",
    "# Create the summary table\n",
    "df_summary = pd.DataFrame(results)\n",
    "\n",
    "# Print it nicely\n",
    "print(df_summary.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
